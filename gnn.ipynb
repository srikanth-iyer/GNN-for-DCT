{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6945456862449646\n",
      "Epoch 100, Loss: 0.00317948660813272\n",
      "Epoch 200, Loss: 0.0010363091714680195\n",
      "Epoch 300, Loss: 0.0005152528756298125\n",
      "Epoch 400, Loss: 0.00030919379787519574\n",
      "Epoch 500, Loss: 0.00020651282102335244\n",
      "Epoch 600, Loss: 0.0001477911719121039\n",
      "Epoch 700, Loss: 0.0001109632576117292\n",
      "Epoch 800, Loss: 8.632027311250567e-05\n",
      "Epoch 900, Loss: 6.898836727486923e-05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Step 1: Generate a 1D Lattice Graph with 3 neighbors on each side\n",
    "def create_1d_lattice_graph(lattice_size=149, neighbors=3):\n",
    "    edges = []\n",
    "    for i in range(lattice_size):\n",
    "        edges.append([i,i]) # self loop\n",
    "        for j in range(1, neighbors + 1):\n",
    "            edges.append([i, (i - j) % lattice_size])  # Connect to left neighbors\n",
    "            edges.append([i, (i + j) % lattice_size])  # Connect to right neighbors\n",
    "\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    return edge_index\n",
    "\n",
    "# Step 2: Define the GNN Model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # First GCN layer + ReLU activation\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        # Second GCN layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "def generate_data(lattice_size=149, sample_size = 100000):\n",
    "    edge_index = create_1d_lattice_graph(lattice_size=lattice_size)\n",
    "    \n",
    "    # Generate random input states for each node\n",
    "    x = torch.randint(0, 2, (lattice_size, 1), dtype=torch.float)\n",
    "    \n",
    "    # Define the binary density classification based on the mean of cell states\n",
    "    y = (x.mean() > 0.5).long().repeat(lattice_size)  # 0 for < 0.5 density, 1 for >= 0.5, repeated to match lattice size\n",
    "    \n",
    "    # Return graph data\n",
    "    return Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "# Step 3: Create the data and model\n",
    "lattice_size = 149\n",
    "edge_index = create_1d_lattice_graph(lattice_size=lattice_size)\n",
    "\n",
    "train_data = generate_data()\n",
    "\n",
    "# Define model, optimizer, and loss function\n",
    "model = GCN(input_dim=1, hidden_dim=16, output_dim=2)  # 2 for binary classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Step 4: Training Loop\n",
    "def train(data, model, optimizer, criterion, epochs=400):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)  # Forward pass\n",
    "        loss = criterion(out, data.y)         # Compute the loss\n",
    "        loss.backward()                       # Backpropagation\n",
    "        optimizer.step()                      # Update the parameters\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# Step 4: Testing Function\n",
    "def test(model, test_data):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient computation for inference\n",
    "        out = model(test_data.x, test_data.edge_index)  # Forward pass\n",
    "        pred = out.argmax(dim=1)  # Get the predicted class (0 or 1)\n",
    "        correct = (pred == test_data.y).sum().item()  # Count correct predictions\n",
    "        accuracy = correct / len(test_data.y)  # Compute accuracy\n",
    "        print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "# Step 5: Run training\n",
    "train(train_data, model, optimizer, criterion, epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_data = generate_data(lattice_size=149)\n",
    "test_accuracy = test(model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of index: 1043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  0,   0,   0,  ..., 148, 148, 148])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index = create_1d_lattice_graph(lattice_size=lattice_size)\n",
    "print(f\"Length of index: {len(edge_index[0])}\")\n",
    "edge_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = generate_data(lattice_size=149)\n",
    "sample.x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
